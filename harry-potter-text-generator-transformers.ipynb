{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# IMPORTS\nimport re\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:31:58.758337Z","iopub.execute_input":"2022-09-12T23:31:58.758909Z","iopub.status.idle":"2022-09-12T23:32:07.642211Z","shell.execute_reply.started":"2022-09-12T23:31:58.758795Z","shell.execute_reply":"2022-09-12T23:32:07.641123Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#DIRECTORIES\nDATASET = \"../input/harry-potter-gru-text-generator\"\nDATA_PATH = \"../input/harry-potter-philosophers-stone-preprocessed/Harry_Potter_philosophers_stone.txt\"\nSAVED_MODEL_PATH = \"../input/harry-potter-gru-text-generator/Best_weights.hdf5\"\nCHECKPOINT_PATH = \"Best_weights.hdf5\"","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:32:07.644452Z","iopub.execute_input":"2022-09-12T23:32:07.645299Z","iopub.status.idle":"2022-09-12T23:32:07.652735Z","shell.execute_reply.started":"2022-09-12T23:32:07.645267Z","shell.execute_reply":"2022-09-12T23:32:07.651735Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Copy file from Input to Output(to easier create a new dataset with updated weights)\nfor file in os.listdir(DATASET):\n    if file.endswith('hdf5') == False:\n        path = os.path.join(DATASET, file)\n        !cp -r $path ./","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the file\ntext = open(DATA_PATH, \"r\", encoding=\"utf-8\").read().lower()\nwords = text.split()","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:32:07.654386Z","iopub.execute_input":"2022-09-12T23:32:07.654995Z","iopub.status.idle":"2022-09-12T23:32:07.685590Z","shell.execute_reply.started":"2022-09-12T23:32:07.654928Z","shell.execute_reply":"2022-09-12T23:32:07.684762Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#text preprocessing\nendings  = ('.', '!', '?')\n\nfor idx, word in enumerate(words):\n    if word.endswith(endings) and word not in endings:\n        words[idx] = re.sub('[.!?]', '', word)\n        words.insert(idx+1, word[-1])\n    if words[idx].startswith('.') and word not in endings:\n        words[idx] = re.sub('[.]', '', word)\n        words.insert(idx-1, '.')\n    if re.search('.[.].', words[idx]):\n        w = word.split('.')\n        words[idx] = '.'\n        words.insert(idx-1, w[0])\n        words.insert(idx+1, w[-1])","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:32:07.687943Z","iopub.execute_input":"2022-09-12T23:32:07.688289Z","iopub.status.idle":"2022-09-12T23:32:07.813232Z","shell.execute_reply.started":"2022-09-12T23:32:07.688254Z","shell.execute_reply":"2022-09-12T23:32:07.812395Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sentences = re.split('[.!?]', text)\nsent = []\nsent = [re.sub('[\\n]', '', sentence) for sentence in sentences]\n\nnew_text = ''.join(sent)\nnew_text = re.sub('  ', ' ', new_text)\nwords = new_text.split()","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:32:07.815608Z","iopub.execute_input":"2022-09-12T23:32:07.816265Z","iopub.status.idle":"2022-09-12T23:32:07.844064Z","shell.execute_reply.started":"2022-09-12T23:32:07.816229Z","shell.execute_reply":"2022-09-12T23:32:07.843161Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Transformers\ntokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\nmodel = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:32:07.845500Z","iopub.execute_input":"2022-09-12T23:32:07.846132Z","iopub.status.idle":"2022-09-12T23:32:36.584267Z","shell.execute_reply.started":"2022-09-12T23:32:07.846096Z","shell.execute_reply":"2022-09-12T23:32:36.583132Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50c69d9058747069cbc5b8688ee2b81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed45d340526d4b5387f006edfa41a976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37697046cc0142e9a3c28bbca7784265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee83ad16ac8d4f62bd2f2044ad102d61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c55f0768b6ff489e9974e381aea3facf"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ndata_token = tokenizer(sent, return_tensors=\"pt\", padding=True, truncation=True, max_length=85)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:35:30.511758Z","iopub.execute_input":"2022-09-12T23:35:30.512257Z","iopub.status.idle":"2022-09-12T23:35:31.205908Z","shell.execute_reply.started":"2022-09-12T23:35:30.512223Z","shell.execute_reply":"2022-09-12T23:35:31.204764Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, random_split\n\nMAX_LENGTH = 85\n\nclass Harry_dataset(Dataset):\n    def __init__(self, sentences, tokenizer, max_length):\n        self.input_ids = []\n        self.attn_masks = []\n        self.labels = []\n        for sentence in sentences:\n            encodings_dict = tokenizer('<|startoftext|>' + sentence + '<|endoftext|>', truncation=True,\n                                       max_length=max_length, padding=\"max_length\")\n            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attn_masks[idx]\n    \n\ndataset = Harry_dataset(sent, tokenizer, max_length=MAX_LENGTH)\ntrain_size = int(0.9 * len(dataset))\ntrain_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:36:42.640509Z","iopub.execute_input":"2022-09-12T23:36:42.640896Z","iopub.status.idle":"2022-09-12T23:36:43.720406Z","shell.execute_reply.started":"2022-09-12T23:36:42.640862Z","shell.execute_reply":"2022-09-12T23:36:43.719440Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir='./', num_train_epochs=10, logging_steps=50, save_steps=5000,\n                                  per_device_train_batch_size=32, per_device_eval_batch_size=64,\n                                  warmup_steps=10, weight_decay=0.05, report_to = 'none')","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:44:35.673790Z","iopub.execute_input":"2022-09-12T23:44:35.674170Z","iopub.status.idle":"2022-09-12T23:44:35.682099Z","shell.execute_reply.started":"2022-09-12T23:44:35.674139Z","shell.execute_reply":"2022-09-12T23:44:35.681073Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\n","output_type":"stream"}]},{"cell_type":"code","source":"Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n                                                              'attention_mask': torch.stack([f[1] for f in data]),\n                                                              'labels': torch.stack([f[0] for f in data])}).train()","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:44:38.203837Z","iopub.execute_input":"2022-09-12T23:44:38.204239Z","iopub.status.idle":"2022-09-12T23:52:47.114151Z","shell.execute_reply.started":"2022-09-12T23:44:38.204190Z","shell.execute_reply":"2022-09-12T23:52:47.113087Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 5895\n  Num Epochs = 10\n  Instantaneous batch size per device = 32\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1850\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1850' max='1850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1850/1850 08:08, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.752900</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.744400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.750500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.714500</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.695400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.686900</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.674300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.662200</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.655800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.646800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.659900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.614800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.624800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.633700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.642800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.604200</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.611500</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.609600</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.605700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.582100</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.602100</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.599700</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.573000</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.570300</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.577000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.588800</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.573100</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.569900</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.561300</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.568300</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.546500</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.572500</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.563500</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.568800</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.555400</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.552700</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.559200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1850, training_loss=0.6182303299774995, metrics={'train_runtime': 488.8808, 'train_samples_per_second': 120.582, 'train_steps_per_second': 3.784, 'total_flos': 1278606145536000.0, 'train_loss': 0.6182303299774995, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"begin = 'Mr. and Mrs. Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you very much. They were the last people youd expect to be involved in anything strange or mysterious because they just didnt hold with such nonsense'\ngenerated = tokenizer(f\"<|startoftext|> {begin}\", return_tensors=\"pt\").input_ids.cuda()\n\nsample_outputs = model.generate(generated, top_k=5, max_length=200, top_p=0.95, temperature=1.95)\n                                \ntokenizer.decode(sample_output, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T23:56:36.880431Z","iopub.execute_input":"2022-09-12T23:56:36.881163Z","iopub.status.idle":"2022-09-12T23:56:36.917095Z","shell.execute_reply.started":"2022-09-12T23:56:36.881126Z","shell.execute_reply":"2022-09-12T23:56:36.915749Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'<|startoftext|> Mr. and Mrs. Dursley of number four Privet Drive were proud to say that they were perfectly normal thank you very much. They were the last people youd expect to be involved in anything strange or mysterious because they just didnt hold with such nonsense. a happy spell harry found them easy once harry had been informed that a large parcel called bdumbledore himself had taken possession o madam gam flitwick from professor dumbledore because they had been given restricted passage when a horrible surprise '"},"metadata":{}}]}]}